# Sign Actions Recognition<br>
Sign language recognition is a technology that aims to interpret and understand sign language gestures performed by individuals, typically those who are deaf or hard of hearing. This technology involves the use of computer vision and machine learning algorithms to analyze and interpret the movements and positions of a person's hands, fingers, and other relevant body parts during sign language communication. By capturing and processing these gestures, sign language recognition systems can convert them into text or spoken language, enabling communication between individuals who use sign language and those who may not be familiar with it. This technology plays a crucial role in bridging communication gaps and promoting inclusivity for the deaf and hard of hearing communities.<br>
## Methodology<br>
Using mediapipe framework the keypoints are captured in the form of .npy file and then it is fed into LSTM model. LSTM model is used here to recognize sequential actions.<br>


